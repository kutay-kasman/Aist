# -*- coding: utf-8 -*-
"""week3_wed_3dkeypoints+angles+acceleration_v5.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Yros56lwuWDJYsQydFT36Prj4PSmSecj

# Data Preparation
"""

# from google.colab import drive
# drive.mount('/content/drive')

import shutil

# Replace this with the actual path to your zip file in Drive
zip_in_drive = "/content/drive/MyDrive/split_pickles.zip"
zip_local_path = "/content/keypoints3d_splitted.zip"

shutil.copy(zip_in_drive, zip_local_path)

import zipfile
import os

# Path to your uploaded zip file
zip_path = "/content/keypoints3d_splitted.zip"

# Target folder to extract into
extract_path = "/content/keypoints3d_splitted"
os.makedirs(extract_path, exist_ok=True)

# Extract the zip file
with zipfile.ZipFile(zip_path, 'r') as zip_ref:
    zip_ref.extractall(extract_path)

print("✅ Extraction complete!")

import pickle

# Example file
file_path = "/content/keypoints3d_splitted/test/gBR_sBM_cAll_d06_mBR2_ch01.pkl"

with open(file_path, "rb") as f:
    data = pickle.load(f)

print("Type:", type(data))
if isinstance(data, dict):
    print("Keys:", data.keys())
    print("Shape of keypoints3d:", data["keypoints3d"].shape)
else:
    print("Shape:", data.shape)

"""# .npz files with 3d keypoints + angles + accelaration + delta angles"""

import os
import pickle
import numpy as np
from tqdm import tqdm

# ✅ Angle utility functions
def unit_vector(v):
    return v / np.linalg.norm(v) if np.linalg.norm(v) != 0 else v

def angle_between(v1, v2):
    v1_u, v2_u = unit_vector(v1), unit_vector(v2)
    dot = np.clip(np.dot(v1_u, v2_u), -1.0, 1.0)
    return np.arccos(dot)

def compute_angles(frame):  # frame: (17, 3)
    angles = []
    kp = frame
    try:
        angles.append(angle_between(kp[11] - kp[13], kp[15] - kp[13]))  # Left Knee
        angles.append(angle_between(kp[12] - kp[14], kp[16] - kp[14]))  # Right Knee
        angles.append(angle_between(kp[5] - kp[7], kp[9] - kp[7]))      # Left Elbow
        angles.append(angle_between(kp[6] - kp[8], kp[10] - kp[8]))     # Right Elbow
        angles.append(angle_between(kp[11] - kp[5], kp[13] - kp[11]))   # Left Hip
        angles.append(angle_between(kp[12] - kp[6], kp[14] - kp[12]))   # Right Hip
        angles.append(angle_between(kp[5] - kp[6], kp[7] - kp[5]))      # Left Shoulder
        angles.append(angle_between(kp[6] - kp[5], kp[8] - kp[6]))      # Right Shoulder
    except:
        angles = [0.0] * 8
    return np.array(angles, dtype=np.float32)

# ✅ Normalization
def normalize_3d(chunk):  # chunk: (60, 17, 3)
    center = chunk[:, 0:1, :]   # pelvis
    chunk = chunk - center
    scale = np.mean(np.linalg.norm(chunk, axis=-1))
    if scale > 0:
        chunk = chunk / scale
    return chunk

# ✅ Paths and settings
input_base = "/content/keypoints3d_splitted"
output_base = "/content/fused_chunks_60"  # changed
chunk_size = 60
splits = ["train", "val", "test"]

# ✅ Create output folders
for split in splits:
    os.makedirs(os.path.join(output_base, split), exist_ok=True)

# ✅ Main loop
for split in splits:
    in_path = os.path.join(input_base, split)
    out_path = os.path.join(output_base, split)

    for fname in tqdm(sorted(os.listdir(in_path)), desc=f"[{split.upper()}]"):
        if not fname.endswith(".pkl"): continue

        genre = fname[1:3].upper()

        with open(os.path.join(in_path, fname), "rb") as f:
            data = pickle.load(f)
            keypoints = data["keypoints3d"]  # (frames, 17, 3)

        for i in range(0, len(keypoints) - chunk_size + 1, chunk_size // 2):
            chunk = keypoints[i:i+chunk_size]
            if chunk.shape != (chunk_size, 17, 3): continue

            chunk = normalize_3d(chunk)

            # ✅ Feature extraction
            poses = chunk.reshape(chunk_size, -1)  # (60, 51)
            angles = np.array([compute_angles(f) for f in chunk])  # (60, 8)

            # ➕ Acceleration
            accel = np.zeros_like(poses)
            accel[1:-1] = poses[2:] - 2 * poses[1:-1] + poses[:-2]

            # ➕ Angle delta
            angle_deltas = np.zeros_like(angles)
            angle_deltas[1:] = angles[1:] - angles[:-1]

            # ✅ Final fusion: (60, 118)
            fused_seq = np.concatenate([poses, angles, accel, angle_deltas], axis=1)

            # 💾 Save
            out_name = f"{fname[:-4]}_chunk{i//chunk_size:03d}.npz"
            save_path = os.path.join(out_path, out_name)
            if not os.path.exists(save_path):
                np.savez_compressed(save_path, seq=fused_seq, label=genre)

print("✅ Done! Saved fused 60-frame sequences →", output_base)

"""# Validation"""

import os
import numpy as np

def clean_all_bad_files(data_dir, splits, min_thresh=-50, max_thresh=50, expected_shape=(60, 118)):
    deleted = 0
    issues = 0

    for split in splits:
        split_path = os.path.join(data_dir, split)
        print(f"\n🔍 Checking split: {split}")

        for fname in sorted(os.listdir(split_path)):
            if not fname.endswith(".npz"):
                continue
            path = os.path.join(split_path, fname)

            try:
                data = np.load(path)
                seq = data["seq"]

                has_issue = False

                # Check shape
                if seq.shape != expected_shape:
                    print(f"❌ Wrong shape in {fname}: got {seq.shape}, expected {expected_shape}")
                    has_issue = True

                # Check NaNs and Infs
                if np.isnan(seq).any():
                    print(f"❌ NaNs in {fname}")
                    has_issue = True
                if np.isinf(seq).any():
                    print(f"❌ Infs in {fname}")
                    has_issue = True

                # Check min/max range
                min_val = np.min(seq)
                max_val = np.max(seq)
                if min_val < min_thresh or max_val > max_thresh:
                    print(f"⚠️ Extreme values in {fname}: min={min_val:.2f}, max={max_val:.2f}")
                    has_issue = True

                # Delete if anything is wrong
                if has_issue:
                    os.remove(path)
                    print(f"🗑️ Deleted {fname}")
                    deleted += 1
                    issues += 1

            except Exception as e:
                print(f"❌ Error loading {fname}: {e}")
                try:
                    os.remove(path)
                    print(f"🗑️ Deleted corrupted file: {fname}")
                    deleted += 1
                    issues += 1
                except PermissionError:
                    print(f"⚠️ Could not delete {fname} (locked or permission issue)")

    if deleted == 0:
        print("\n✅ All .npz files look clean!")
    else:
        print(f"\n🧹 Deleted {deleted} bad files with issues.")

# ✅ Run cleanup for 60-frame, 118-dim fused input features
clean_all_bad_files(
    data_dir="/content/fused_chunks_60",
    splits=["train", "val", "test"],
    min_thresh=-50,
    max_thresh=50,
    expected_shape=(60, 118)
)

"""# Save .npz files to Drive"""

import shutil

shutil.make_archive("/content/fused_chunks_60_bi", 'zip', "/content/fused_chunks_60")

import shutil

# Move the zip file to your Drive
shutil.move(
    "/content/fused_chunks_60_bi.zip",
    "/content/drive/MyDrive/fused_chunks_60_bi.zip"
)

"""# Dataset Loader"""

from torch.utils.data import Dataset
import torch
import os
import numpy as np
import torch.nn as nn


# 🎭 Genre label mapping
genre_to_idx = {
    'BR': 0, 'HO': 1, 'JB': 2, 'JS': 3, 'KR': 4,
    'LH': 5, 'LO': 6, 'MH': 7, 'PO': 8, 'WA': 9
}

# 📦 FusedPoseDataset: supports 60×118 input (keypoints + angles + deltas + accel)
class FusedPoseDataset(Dataset):
    def __init__(self, folder_path):
        self.samples = []
        for file in os.listdir(folder_path):
            if not file.endswith(".npz"):
                continue

            path = os.path.join(folder_path, file)
            try:
                data = np.load(path)
                seq = data["seq"]  # shape: (60, 118)
                label_str = str(data["label"])  # e.g. 'BR'
                label = genre_to_idx.get(label_str, -1)

                # ✅ Safety check
                if label == -1 or seq.shape != (60, 118):
                    print(f"⚠️ Skipping {file}: shape={seq.shape}, label={label_str}")
                    continue

                self.samples.append((
                    torch.tensor(seq, dtype=torch.float32),      # (60, 118)
                    torch.tensor(label, dtype=torch.long)        # class index
                ))
            except Exception as e:
                print(f"❌ Error loading {file}: {e}")
                continue

    def __len__(self):
        return len(self.samples)

    def __getitem__(self, idx):
        return self.samples[idx]

"""# Define LSTM Model"""

import torch.nn as nn

class DanceLSTM(nn.Module):
    def __init__(self, input_size=118, hidden_size=128, num_layers=2, num_classes=10):
        super().__init__()
        self.lstm = nn.LSTM(
            input_size, hidden_size, num_layers,
            batch_first=True, bidirectional=True, dropout=0.3  # ⬅️ Dropout added
        )
        self.dropout = nn.Dropout(0.3)  # ⬅️ Extra safety
        self.fc = nn.Linear(hidden_size * 2, num_classes)

    def forward(self, x):  # x: (B, 60, 118)
        out, _ = self.lstm(x)
        out = self.dropout(out[:, -1, :])  # ⬅️ Apply dropout at final time step
        return self.fc(out)

"""# Train Model"""

from torch.utils.data import DataLoader
import torch
from tqdm import tqdm
from torch.optim import Adam
import os

# ✅ Use the updated 60-frame fused input folder
DATA_DIR = "/content/fused_chunks_60"  # ← changed from _120

# ✅ Load fused datasets (60, 118)
train_set = FusedPoseDataset(os.path.join(DATA_DIR, "train"))
val_set   = FusedPoseDataset(os.path.join(DATA_DIR, "val"))

# ✅ DataLoaders
train_loader = DataLoader(train_set, batch_size=16, shuffle=True)
val_loader   = DataLoader(val_set, batch_size=16)

# ✅ Device
DEVICE = torch.device("cuda" if torch.cuda.is_available() else "cpu")

# ✅ Model for (60, 118) input
model = DanceLSTM(input_size=118).to(DEVICE)  # no change here

# ✅ Optimizer and Loss
optimizer = Adam(model.parameters(), lr=0.001)
criterion = torch.nn.CrossEntropyLoss()

# ✅ Track best model
best_val_acc = 0.0

# ✅ Training loop
EPOCHS = 50
for epoch in range(1, EPOCHS + 1):
    model.train()
    total_loss = 0

    for X, y in tqdm(train_loader, desc=f"Epoch {epoch}"):
        X, y = X.to(DEVICE), y.to(DEVICE)
        optimizer.zero_grad()
        out = model(X)  # (B, 10)
        loss = criterion(out, y)
        loss.backward()
        optimizer.step()
        total_loss += loss.item()

    # ✅ Validation
    model.eval()
    correct = total = 0
    with torch.no_grad():
        for X, y in val_loader:
            X, y = X.to(DEVICE), y.to(DEVICE)
            preds = model(X).argmax(dim=1)
            correct += (preds == y).sum().item()
            total += y.size(0)

    val_acc = correct / total * 100
    print(f"✅ Epoch {epoch}: Train Loss = {total_loss:.4f}, Val Accuracy = {val_acc:.2f}%")

    # 💾 Save best model
    if val_acc > best_val_acc:
        best_val_acc = val_acc
        torch.save(model.state_dict(), "best_dance_lstm_60.pth")  # ← renamed to avoid overwrite
        print(f"📦 Saved new best model (val acc = {val_acc:.2f}%)")

MODEL_PATH = "/content/best_dance_lstm_60.pth"
torch.save(model.state_dict(), MODEL_PATH)
print(f"💾 Model saved to {MODEL_PATH}")

# from google.colab import drive
# drive.mount('/content/drive')

# # Copy the model to your Google Drive
# !cp /content/best_dance_lstm_60.pth /content/drive/MyDrive/
# print("✅ Model copied to Google Drive: MyDrive/best_dance_lstm_60.pth")

# """# Test"""

from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay
import matplotlib.pyplot as plt
import torch
import numpy as np
import os

# ✅ Genre index → label name
idx_to_genre = {v: k for k, v in genre_to_idx.items()}

# ✅ Load test set
test_set = FusedPoseDataset(os.path.join("/content/fused_chunks_60", "test"))
test_loader = DataLoader(test_set, batch_size=32)

# ✅ Load model with correct input size
model = DanceLSTM(input_size=118).to(DEVICE)
model.load_state_dict(torch.load("/content/drive/MyDrive/best_dance_lstm_60.pth"))
model.eval()

top1_correct = 0
top3_correct = 0
total = 0
all_preds = []
all_labels = []

with torch.no_grad():
    for X, y in test_loader:
        X, y = X.to(DEVICE), y.to(DEVICE)
        logits = model(X)
        top3 = torch.topk(logits, k=3, dim=1).indices  # (B, 3)

        # Top-1
        preds = top3[:, 0]
        top1_correct += (preds == y).sum().item()

        # Top-3
        for i in range(y.size(0)):
            if y[i] in top3[i]:
                top3_correct += 1

        total += y.size(0)
        all_preds.extend(preds.cpu().numpy())
        all_labels.extend(y.cpu().numpy())

# ✅ Accuracy results
top1_acc = top1_correct / total * 100
top3_acc = top3_correct / total * 100
print(f"🎯 Top-1 Accuracy: {top1_acc:.2f}%")
print(f"🏅 Top-3 Accuracy: {top3_acc:.2f}%")

# ✅ Confusion Matrix
cm = confusion_matrix(all_labels, all_preds)
disp = ConfusionMatrixDisplay(cm, display_labels=[idx_to_genre[i] for i in range(10)])
disp.plot(cmap='Blues', xticks_rotation=45)
plt.title("Confusion Matrix")
plt.show()